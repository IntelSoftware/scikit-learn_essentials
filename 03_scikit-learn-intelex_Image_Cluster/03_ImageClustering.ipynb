{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "599e019e",
   "metadata": {},
   "source": [
    "# 03 ImageClustering using PCA, Kmeans, DBSCAN\n",
    "\n",
    "\n",
    "![Assets/dbscan_graph.png](Assets/dbscan_graph.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7719ef49",
   "metadata": {},
   "source": [
    "\n",
    "## Learning Objectives\n",
    "\n",
    "* Explore and interpret the image dataset\n",
    "\n",
    "* Apply Intel® Extension for Scikit-learn* patches to Principal Components Analysis (PCA), Kmeans,and DBSCAN algorithms and target GPU\n",
    "\n",
    "## Library Dependencies:\n",
    "\n",
    " - **pip install pickle**\n",
    " - **pip install pillow**\n",
    " - **pip install seaborn**\n",
    " - also requires these libraries if they are not already installed: **matplotlib, numpy, pandas, sklearn**\n",
    "\n",
    "<a id='Back_to_Sections'></a>\n",
    "\n",
    "## Sections\n",
    "\n",
    "- _Code:_ [Read Images](#Define-image-manipulation-and-Reading-functions)\n",
    "- _Code:_ [Submit batch_clustering_Streamlined.py as a batch job](#Submit-batch_clustering_Streamlined.py-as-a-batch-job)\n",
    "- _Code:_ [Read the results of the dictionary after GPU computation](#Read-the-results-of-the-dictionary-after-GPU-computation)\n",
    "- _Code:_ [Plot Kmeans using GPU results](#Plot-Kmeans)\n",
    "- _Code:_ [Plot DBSCAN using GPU results](#Plot-DBSCAN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d0d31c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T03:35:22.700065Z",
     "start_time": "2021-10-06T03:35:22.693041Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "data_path = ['data']\n",
    "\n",
    "# Notebook time start\n",
    "from datetime import datetime\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "current_time = start_time.strftime(\"%H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23938fb",
   "metadata": {},
   "source": [
    "# Define image manipulation and Reading functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b17e812",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-30T23:14:00.614891Z",
     "start_time": "2021-09-30T23:14:00.603207Z"
    }
   },
   "outputs": [],
   "source": [
    "from lab.Read_Transform_Images import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbc9b30",
   "metadata": {},
   "source": [
    "<a id='Actually-read-the-images'></a>\n",
    "# Actually read the images\n",
    "\n",
    "- [Back to Sections](#Back_to_Sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935125a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T03:35:32.344246Z",
     "start_time": "2021-10-06T03:35:24.446381Z"
    }
   },
   "outputs": [],
   "source": [
    "resultsDict = {}\n",
    "#resultsDict = Read_Transform_Images(resultsDict,imagesFilenameList = imagesFilenameList)\n",
    "resultsDict = Read_Transform_Images(resultsDict)\n",
    "#resultsDict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e0f896-8f55-4a0c-b28f-8a7977011d06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bbdfcd12-03d9-40e3-b245-6845189a3ec0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T03:19:44.061110Z",
     "start_time": "2021-10-06T03:19:44.053079Z"
    }
   },
   "source": [
    "# Display ImageGrid Random Sampling\n",
    "\n",
    "This should give an idea of how closely or differently the various images appear. Notice that some of the collard lizard images have much differnet white balance and this will affect the clustering. For this dataset the images are clustered based on the similarity in RGB colorspace only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28840f2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T03:35:36.643550Z",
     "start_time": "2021-10-06T03:35:32.344246Z"
    }
   },
   "outputs": [],
   "source": [
    "img_arr = []\n",
    "ncols = 8\n",
    "imageGrid=(ncols,3)\n",
    "for pil in random.sample(resultsDict['list_PIL_Images'], imageGrid[0]*imageGrid[1])  :\n",
    "    img_arr.append(np.array(pil))\n",
    "#displayImageGrid(img_arr, imageGrid=imageGrid)\n",
    "displayImageGrid2(img_arr, ncols=ncols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e04f1d",
   "metadata": {},
   "source": [
    "<a id='Review_python_batch_file_prior_to_submission'></a>\n",
    "\n",
    "# Review Python file prior to submission\n",
    "### Set SYCL Device Context\n",
    "\n",
    "\n",
    "- [Back to Sections](#Back-to-Sections)\n",
    "\n",
    "Paste this code in cell below and run it (twice) once to load, once to execute the cell:\n",
    "\n",
    "%load batch_clustering_Streamlined.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12826de6-079c-49ea-986a-52c4499a7bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load batch_clustering_Streamlined.py\n",
    "# batch_clustering_Streamlined.py\n",
    "\n",
    "\n",
    "#===============================================================================\n",
    "# Copyright 2014-2021 Intel Corporation\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "#===============================================================================\n",
    "\n",
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "from PIL import Image\n",
    "from PIL.Image import Image as PilImage\n",
    "#from skimage.color import rgb2hsv\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import DBSCAN\n",
    "import pandas as pd\n",
    "import random\n",
    "import operator\n",
    "import seaborn as sns\n",
    "import json\n",
    "\n",
    "def ReshapeShortFat(original):\n",
    "    \"\"\"\n",
    "    ReshapeShortFat(original)\n",
    "    \n",
    "    Reshapes the image numpy array from original shape \n",
    "    to the ShortFat single row shape and captures\n",
    "    shape info in the output:\n",
    "    channel_0, channel_1, channel_2\n",
    "    \n",
    "    functionally performs original.reshape(1, x*y*z) to create single row vector\n",
    "    \n",
    "    inputs:\n",
    "        original - input the original image array\n",
    "    \n",
    "    return:\n",
    "        ShortFatArray\n",
    "        channel_0 - dimensions of the first channel - possibly the Red channel if using RGB\n",
    "        channel_1 - dimensions of the first channel - possibly the Green channel if using RGB\n",
    "        channel_2 - dimensions of the first channel - possibly the Blue channel if using RGB\n",
    "    \"\"\"       \n",
    "    # preserve shape of incoming image\n",
    "    channel_0, channel_1, channel_2 = original.shape\n",
    "    #print('a shape ', a.shape)\n",
    "\n",
    "    # convert to short, fat array\n",
    "    ShortFatArray = original.reshape(1, channel_0*channel_1*channel_2)\n",
    "\n",
    "    #print('a1 shape ', a1.shape)\n",
    "    return ShortFatArray.squeeze(), channel_0, channel_1, channel_2\n",
    "\n",
    "def Read_Transform_Images(resultsDict, \n",
    "                         imagesFilenameList = [], \n",
    "                         FSWRITE = False): \n",
    "    print('Running Read_Transform_Images on CPU: ')\n",
    "    imageToClusterPath = 'data/'\n",
    "    if len(imagesFilenameList) == 0:\n",
    "        imagesFilenameList = [f for f in \n",
    "            sorted(glob.glob(imageToClusterPath \n",
    "            + '*.jpg'))]\n",
    "\n",
    "    list_np_Images = []\n",
    "    list_PIL_Images = []\n",
    "    for im in imagesFilenameList:\n",
    "        img =  Image.open(im)\n",
    "        list_PIL_Images.append(img)\n",
    "        a = np.asarray(img,dtype=np.float32)/255\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            #a1, x, y, z = ReshapeShortFat(rgb2hsv(a))\n",
    "            a1, x, y, z = ReshapeShortFat(a)\n",
    "        a2 = a1  # no image whitening for each file\n",
    "        list_np_Images.append(a2)\n",
    "    NP_images = np.array(list_np_Images)\n",
    "    NP_images_STD = StandardScaler(with_std=True).fit_transform(NP_images)\n",
    "    resultsDict['imagesFilenameList'] = imagesFilenameList\n",
    "    resultsDict['list_PIL_Images'] = list_PIL_Images\n",
    "    resultsDict['NP_images_STD'] = NP_images_STD\n",
    "    if FSWRITE == True:\n",
    "        write_results(resultsDict)\n",
    "    return resultsDict\n",
    "\n",
    "def displayImageGrid(img_arr, imageGrid=(4,5)):\n",
    "    import matplotlib.pyplot as plt\n",
    "    from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "    import numpy as np\n",
    "    import random\n",
    "\n",
    "    fig = plt.figure(figsize=(20,20))\n",
    "    grid = ImageGrid(fig, 111, \n",
    "                     nrows_ncols=imageGrid,  # creates 2x2 grid of axes\n",
    "                     #axes_pad=0.1,  # pad between axes\n",
    "                     )\n",
    "\n",
    "    img_arr = np.array(img_arr)\n",
    "    for ax, im in zip(grid, img_arr):\n",
    "         ax.imshow(im)\n",
    "\n",
    "    plt.show()\n",
    "   \n",
    "    \n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "    \n",
    "def write_results_json(resultsDict):\n",
    "    if 'list_PIL_Images' in resultsDict.keys():\n",
    "        del resultsDict['list_PIL_Images']\n",
    "    if 'NP_images_STD' in resultsDict.keys():\n",
    "        del resultsDict['NP_images_STD']\n",
    "    with open(\"results/resultsDict.json\", \"w\") as outfile:\n",
    "        json.dump(resultsDict, outfile, cls=NumpyEncoder)\n",
    "\n",
    "def read_results_json():\n",
    "    with open('results/resultsDict.json') as json_file:\n",
    "        resultsDict = json.load(json_file)\n",
    "    return resultsDict\n",
    "\n",
    "def main():\n",
    "    # determine if GPU available:\n",
    "    dpctl_available = False\n",
    "    try:\n",
    "        import dpctl\n",
    "        from sklearnex._config import config_context\n",
    "        dpctl_available = True\n",
    "    except ImportError:\n",
    "        try:\n",
    "            from daal4py.oneapi import sycl_context\n",
    "            print(\"*\" * 80)\n",
    "            print(\"\\ndpctl package not found, switched to daal4py package\\n\")\n",
    "            print(\"*\" * 80)\n",
    "        except ImportError:\n",
    "            print(\"\\nRequired packages not found, aborting...\\n\")\n",
    "            exit()\n",
    "\n",
    "    devices = []\n",
    "    gpu_available = False\n",
    "    if not dpctl_available:\n",
    "        try:\n",
    "            with sycl_context('gpu'):\n",
    "                gpu_available = True\n",
    "        except Exception:\n",
    "            gpu_available = False\n",
    "\n",
    "\n",
    "    def get_context(device):\n",
    "        if dpctl_available:\n",
    "            return config_context(target_offload=device)\n",
    "        return sycl_context(device)\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "    resultsDict = {}\n",
    "    resultsDict = Read_Transform_Images(resultsDict)\n",
    "    knee = 6\n",
    "    EPS = 350\n",
    "    n_components = 6\n",
    "    n_samples = 3\n",
    "    NP_images_STD = resultsDict['NP_images_STD'] # images as numpy array\n",
    "    # It is possible to specify to make the computations on GPU\n",
    "    if gpu_available:\n",
    "        print('Running ComputePCA on GPU: ')   \n",
    "        device_context = 'gpu'\n",
    "        with  get_context('gpu'):           \n",
    "            pca = PCA(n_components=n_components)\n",
    "            PCA_fit_transform = pca.fit_transform(NP_images_STD) \n",
    "            k_means = KMeans(n_clusters = knee, init='random')\n",
    "            db = DBSCAN(eps=EPS, min_samples = n_samples).fit(PCA_fit_transform)\n",
    "            km = k_means.fit(PCA_fit_transform)\n",
    "    # It is possible to specify to make the computations on CPU\n",
    "    else:\n",
    "        print('Running ComputePCA on local CPU: ')\n",
    "        device_context = 'cpu'\n",
    "        pca = PCA(n_components=n_components)\n",
    "        PCA_fit_transform = pca.fit_transform(NP_images_STD) \n",
    "        k_means = KMeans(n_clusters = knee, init='random')\n",
    "        db = DBSCAN(eps=EPS, min_samples = n_samples).fit(PCA_fit_transform)\n",
    "        km = k_means.fit(PCA_fit_transform) \n",
    "\n",
    "    resultsDict['device_context'] = device_context\n",
    "    resultsDict['imageClusters_db'] = len(np.unique(db.labels_))\n",
    "    resultsDict['counts_db'], resultsDict['bins_db']  = np.histogram(db.labels_, bins = EPS)\n",
    "    resultsDict['counts'], resultsDict['bins'] =np.histogram(k_means.labels_, bins = knee)    \n",
    "    resultsDict['imageClusters'] = len(np.unique(km.labels_))\n",
    "    resultsDict['km_labels'] = km.labels_\n",
    "    resultsDict['db_labels'] = db.labels_\n",
    "    resultsDict['PCA_fit_transform'] = PCA_fit_transform\n",
    "    \n",
    "    \n",
    "    write_results_json(resultsDict)\n",
    "    \n",
    "    print(\"Kmeans bins   \", resultsDict['bins'])\n",
    "    print(\"Kmeans counts \", resultsDict['counts'])\n",
    "    \n",
    "    print(\"All good inside main\\n\")\n",
    "    \n",
    "    return resultsDict\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    resultsDict = main()\n",
    "    #print(\"km_list: \", resultsDict['km_list'][0:2])\n",
    "    print('All looks good!\\nRun 03_Plot_GPU_Results.ipynb to graph the results!')\n",
    "\n",
    "# Notices & Disclaimers \n",
    "\n",
    "# Intel technologies may require enabled hardware, software or service activation.\n",
    "# No product or component can be absolutely secure.\n",
    "\n",
    "# Your costs and results may vary.\n",
    "\n",
    "# © Intel Corporation. Intel, the Intel logo, and other Intel marks are trademarks of Intel Corporation or its subsidiaries. \n",
    "# *Other names and brands may be claimed as the property of others.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14018032-c40c-4887-8f07-a31a754efae3",
   "metadata": {},
   "source": [
    "<a id='Submit-batch_clustering_Streamlined.py-as-a-batch-job'></a>\n",
    "# Submit batch_clustering_Streamlined.py\n",
    "\n",
    "- [Back to Sections](#Back_to_Sections)\n",
    "\n",
    "batch_clustering_Streamlined.py executed with a Python* command inside a shell script - run_clustering_streamlined.sh.\n",
    "\n",
    "run_clustering_streamlined.sh is submitted as a batch job to a node which has GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0acf897-265b-4f24-8df9-49b395a5c32d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T03:36:04.714935Z",
     "start_time": "2021-10-06T03:36:04.656944Z"
    }
   },
   "outputs": [],
   "source": [
    "#!python batch_kmeans.py   # works on Windows\n",
    "! chmod 755 q; chmod 755 run_clustering_streamlined.sh; if [ -x \"$(command -v qsub)\" ]; then ./q run_clustering_streamlined.sh; else ./run_clustering_streamlined.sh; fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77093e3-e041-4043-bb8d-e0f0f2c36008",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id='Read-the-results-of-the-dictionary-after-GPU-computation'></a>\n",
    "# Read Results of the Dictionary After GPU Computation\n",
    "\n",
    "- [Back to Sections](#Back_to_Sections)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf8e2ff-518f-4f95-a33f-7a7ca5316b51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T03:36:04.778981Z",
     "start_time": "2021-10-06T03:36:04.716938Z"
    }
   },
   "outputs": [],
   "source": [
    "# read results from json file in results folder\n",
    "resultsDict = read_results_json()\n",
    "# get list_PIL_Images from Read_Tansform_Images\n",
    "resultsDict = Read_Transform_Images(resultsDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd5bafe-42bd-45c3-82bd-3aa54b65d0c8",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id='Plot-Kmeans'></a>\n",
    "# Plot Kmeans Clusters \n",
    "\n",
    "Plot a histogram of the using GPU results\n",
    "-  [Back to Sections](#Back_to_Sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab272b4f-f6d5-455c-84c1-ad9f361f827d",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsDict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a00148-a8dd-460e-9721-39aa52655a5c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T03:36:06.710515Z",
     "start_time": "2021-10-06T03:36:06.475484Z"
    }
   },
   "outputs": [],
   "source": [
    "#resultsDict = Compute_kmeans_db_histogram_labels(resultsDict, knee = 6, gpu_available = gpu_available) #knee = 5\n",
    "counts = np.asarray(resultsDict['counts'])\n",
    "bins = np.asarray(resultsDict['bins'])\n",
    "plt.xlabel(\"Weight\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.title(\"Histogram with Probability Plot: Context {}\".format(resultsDict['device_context']))\n",
    "slice = min(counts.shape[0], bins.shape[0])\n",
    "plt.bar(bins[:slice],counts[:slice])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc11c68-a7c4-4c02-8642-745d4bca7db8",
   "metadata": {},
   "source": [
    "# Print Kmeans Related Data as a Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3676b1-f88b-477d-bc76-2e443524044e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resultsDict['bins'])\n",
    "print(resultsDict['counts'])\n",
    "resultsDict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e96d3fc-7ce3-4fcf-af37-7976bf4dca3e",
   "metadata": {},
   "source": [
    "# Display Similar Images\n",
    "\n",
    "Visually compare image which have been clustered by the allgorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1a430c-3a61-4b43-9d33-e0d0f056bc72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T03:36:10.547299Z",
     "start_time": "2021-10-06T03:36:06.712486Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "clusterRank = 1\n",
    "d = {i:cts for i, cts in enumerate(resultsDict['counts'])}\n",
    "sorted_d = sorted(d.items(), key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "id = sorted_d[clusterRank][0]\n",
    "indexCluster = np.where(np.asarray(resultsDict['km_labels']) == id  )[0].tolist()\n",
    "img_arr = []\n",
    "for idx in indexCluster:\n",
    "    img_arr.append(np.array((resultsDict['list_PIL_Images'][idx])))\n",
    "img_arr = np.asarray(img_arr)\n",
    "displayImageGrid(img_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0b7104-05eb-45a4-b363-182f37d94f13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T03:36:10.594867Z",
     "start_time": "2021-10-06T03:36:10.549295Z"
    }
   },
   "source": [
    "# PlotPlot Seaborn Kmeans Clusters\n",
    "\n",
    "Indicates numbers of images that are close in color space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47da733b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T03:36:17.302892Z",
     "start_time": "2021-10-06T03:36:10.596866Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "n_components = 4\n",
    "\n",
    "columns = ['PC{:0d}'.format(c) for c in range(n_components)]\n",
    "data = pd.DataFrame(np.asarray(resultsDict['PCA_fit_transform'])[:,:n_components], columns = columns)\n",
    "#k_means = resultsDict['model']\n",
    "data['cluster'] = resultsDict['km_labels']\n",
    "data.head()\n",
    "# similarlyNamedImages = [9,6,6,8,6,4,8,3]\n",
    "# print('number of similarly named images: ', similarlyNamedImages)\n",
    "\n",
    "columns.append('cluster')\n",
    "plt.figure(figsize=(8,8))\n",
    "\n",
    "sns.set_context('notebook');\n",
    "g = sns.pairplot(data[columns], hue=\"cluster\", palette=\"Paired\", diag_kws=dict(hue=None));\n",
    "g.fig.suptitle(\"KMEANS pairplot: Context {}\".format(resultsDict['device_context']));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6117eff7-5f57-473d-91a5-9adf541cadff",
   "metadata": {},
   "source": [
    "# Find DBSCAN EPS parameter\n",
    "\n",
    "Density-Based Spatial Clustering of Applications with Noise (DBSCAN) finds core samples of high density and expands clusters from them. Good for data which contains clusters of similar density.\n",
    "\n",
    "EPS: \"epsilon\" value in sklearn is the maximum distance between two samples for one to be considered as in the neighborhood of the other.\n",
    "\n",
    "At least a first value to start. We are using kNN to find distances commonly occuring in the dataset. Values of EPS below this threshold distance will be considered as lyig within a given cluster. This means we should look for long flat plateaus and read the y coordinate off the kNN plot to get a starting value for EPS.\n",
    "\n",
    "Different datasets can have wildly different sweet spots for EPS. Some datasets require EPS values of .001 other datasets may work best with values of EPS of several thousand. We use this trick to get in the right or approximate neighborhood of the EPS.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7563130-17e1-4ea1-bbb7-503ddee77d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "PCA_images = resultsDict['PCA_fit_transform']\n",
    "\n",
    "neighbors = NearestNeighbors(n_neighbors=2)\n",
    "#X = StandardScaler().fit_transform(PCA_images)\n",
    "neighbors_fit = neighbors.fit(PCA_images)\n",
    "distances, indices = neighbors_fit.kneighbors(PCA_images)\n",
    "\n",
    "distances = np.sort(distances, axis=0)\n",
    "plt.xlabel('number of images')\n",
    "plt.ylabel('distances')\n",
    "plt.title('KNN Distances Plot')\n",
    "plt.plot(distances[:,1])\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5bbc10-0d01-47e8-b6f4-5abaf159de1c",
   "metadata": {},
   "source": [
    "# Use DBSCAN to find clusters\n",
    "\n",
    "we will use initial estiamtes from KNN above (find elbow) to given initial trial for DBSCAN EPS values \n",
    "\n",
    "In the plot above, there is a plateau in the y values somewherre near 350 indicating that a cluster distance (aka EPS) might work well somewhere near this value. We used this value in the batch_clustering_Streamlined.py file when computing DBSCAN.\n",
    "\n",
    "**EPS:** Two points are  neighbors if the distance between the two points is below a threshold.\n",
    "**n:** The minimum number of neighbors a given point should have in order to be classified as a core point. \n",
    "The point itself is included in the minimum number of samples.\n",
    "\n",
    "# Below: Sort DBSCAN Results by Cluster Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0cd669-2581-4f5c-af1b-8292eb1fd557",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%write_and_run    lab/compute_DBSCANClusterRank.py \n",
    "def compute_DBSCANClusterRank(n, EPS):\n",
    "    d = {index-1:int(cnt) for index, cnt in enumerate(counts )}\n",
    "    sorted_d = sorted(d.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    for i in range(0, len(d)):\n",
    "        idx = sorted_d[i][0]\n",
    "        print('cluster = ', idx, ' occurs', int(sorted_d[i][1]), ' times')\n",
    "    return db, counts, bins, sorted_d\n",
    "\n",
    "n_components = 4\n",
    "\n",
    "columns = ['PC{:0d}'.format(c) for c in range(n_components)]\n",
    "data = pd.DataFrame(np.asarray(resultsDict['PCA_fit_transform'])[:,:n_components], columns = columns)\n",
    "\n",
    "columns.append('cluster')\n",
    "data['cluster'] = resultsDict['db_labels'] \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb95f1b7-dd09-4513-9771-9254f84a9f7e",
   "metadata": {},
   "source": [
    "<a id='Plot-DBSCAN'></a>\n",
    "# DBSCAN Cluster Plot\n",
    "\n",
    "Plot a histogram of the using GPU results\n",
    "- [Back to Sections](#Back_to_Sections)\n",
    "\n",
    " \n",
    "\n",
    "To indicate numbers of images in each cluster. color each point by its membership in a cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e69a78c-c77e-43a6-967b-bd493195b0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "sns.set_context('notebook');\n",
    "g = sns.pairplot(data[columns], hue=\"cluster\", palette=\"Paired\", diag_kws=dict(hue=None));\n",
    "g.fig.suptitle(\"DBSCAN pairplot: Context {}\".format(resultsDict['device_context']));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9a43d8-b6fe-47ca-8f35-b28edd664dea",
   "metadata": {},
   "source": [
    "# Print Filenames of Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e283baef-d9c1-4e5c-b7a9-2198c741d47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Outlier/problematic images are: \\n', \n",
    "      [resultsDict['imagesFilenameList'][f] for f in list(data[data['cluster'] == -1].index)]\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f43c36b-7574-438f-9114-31694fc74dbb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Final Thoughts and next steps...\n",
    "\n",
    "You may have noticed how difficult it is to get decent clustering on even 30 or 40 images using only RGB or HSV as the feature set\n",
    ".\n",
    "If all the images are well separated in either RGB, or HSV color space, then these features are useful for clustering.\n",
    "\n",
    "However, a suggested next step—or next training—would be to encode the data differently. Perhaps using image classification with VGG16, but removing the last layer as a preprocess prior to k-means or DBSCAN.\n",
    "\n",
    "\n",
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e2b8dd-1cf5-4645-ad4c-c8855a35eacf",
   "metadata": {},
   "source": [
    "# Notices & Disclaimers \n",
    "\n",
    "Intel technologies may require enabled hardware, software or service activation.\n",
    "No product or component can be absolutely secure.\n",
    "\n",
    "Your costs and results may vary.\n",
    "\n",
    "© Intel Corporation. Intel, the Intel logo, and other Intel marks are trademarks of Intel Corporation or its subsidiaries. \n",
    "*Other names and brands may be claimed as the property of others.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2560e272-ba6d-4536-adec-058081a8793d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (Intel® oneAPI)",
   "language": "python",
   "name": "c009-intel_distribution_of_python_3_oneapi-beta05-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
